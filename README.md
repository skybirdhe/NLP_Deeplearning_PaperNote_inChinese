# NLP Deeplearning PaperNote
####2017-2
ICLR 2017 Accpeted Paper I have read / am going to read [[ICLR](https://openreview.net/group?id=ICLR.cc/2017/conference)]

<li>A Compare-Aggregate Model for Matching Text Sequences. 实验很solid

<li>Dynamic Coattention Networks For Question Answering. DMN做阅读理解

<li>Pointer Sentinel Mixture Models. 开放了一个LM数据集，模型是PointerNetwork的延伸
####2017-1
<li>Wasserstein GAN[[ArXiv](https://arxiv.org/pdf/1701.06547)] 重剑无锋，大巧不工。用深度的数学理论推导出了简单易懂的GAN训练方法</li>
<li>Adversarial Learning for Neural Dialogue Generation[[ArXiv](https://arxiv.org/pdf/1701.06547)] 大哥确实动手快，感觉需要这篇paper的code~</li>
<li>DeepStack: Expert-Level Artificial Intelligence in No-Limit Poker[[ArXiv](https://arxiv.org/abs/1701.01724)] 这篇论文的AI可以平局每局赢450mbb，至少可以拿来赚钱了</li>
<li>DyNet: The Dynamic Neural Network Toolkit [[ArXiv](https://arxiv.org/pdf/1701.03980.pdf)] 知情人士表示，在很多种情况下TF比DyNet快</li>


####2016-12

<li>Language Modeling with Gated Convolutional Networks[[ArXiv](https://arxiv.org/abs/1612.08083)]如果说有什么亮眼的可能是快。。。</li>

<li>Sequential Match Network: A New Architecture for Multi-turn Response Selection in Retrieval-based Chatbots [[ArXiv](https://arxiv.org/abs/1612.01627)]</li>

<li>Learning Through Dialogue Interactions [[ArXiv](https://arxiv.org/abs/1612.04936)]</li>

<li>A Simple, Fast Diverse Decoding Algorithm for Neural Generation[[ArXiv](https://arxiv.org/abs/1611.08562)]</li>

